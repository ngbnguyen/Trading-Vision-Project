# import packages
import pandas as pd
import numpy as np
from datetime import datetime

from sklearn.linear_model import LinearRegression

# For polynomial regression
from sklearn.preprocessing import PolynomialFeatures

import matplotlib.pyplot as plt

#  Choose time and close price columns
col_lists = ["<Ticker>", "<DTYYYYMMDD>", "<Close>"]
# Specify date format
def parser(x):
    return datetime.strptime(x, "%Y%m%d")


# df = pd.read_csv('D:\PROJECT\CODE\SourceCode\CodeAlgoSVM\HSX.csv', usecols=col_lists)
df = pd.read_csv(
    "HSX_old.csv",
    header=0,
    index_col="<DTYYYYMMDD>",
    parse_dates=["<DTYYYYMMDD>"],
    usecols=col_lists,
)
df.columns = ["Ticker", "Close"]
# print (df.head())
df.index = (df.index - pd.to_datetime("1970-01-01")).days

# Get ticker ACB
ticker = "VNM"
df = df[df["Ticker"] == ticker]
df = df.sort_values('<DTYYYYMMDD>')

# print (df.head())

# Coverting the pandas series into numpy array, we need to further check
# massage it before sending it to regression model
y = np.asarray(df["Close"])
x = np.asarray(df.index.values)

# print('X = ', x)
# print('Y = ', y)

# Model initialization
# by default the degree of the equation is 1.
# Hence the mathematical model equation is y = mx + c
# which is an equation of a line.
regression_model = LinearRegression()

# Choose the order of your polynomial. Here the degree is set to 5.
# hence the mathematical model equation is
# y = c0 + c1.x + c2.x^2 + ... + c5.x^5
poly = PolynomialFeatures(4)

# Convert dimension x in the higher degree polynomial expression
X_transform = poly.fit_transform(x.reshape(-1, 1))

# Fit the data(train the model)
regression_model.fit(X_transform, y.reshape(-1, 1))

# Prediction for historical dates. Let's call it learned values.
y_learned = regression_model.predict(X_transform)

# print(y_learned[:10])

# Now, add future dates to the date index and pass that index to the regression model for future prediction
# As we have converted date index into a range index, hence, here we just need to add 5 days
# to the previous index. x[-1] gives the last value of the series.
newindex = np.asarray(pd.RangeIndex(start=x[-1], stop=x[-1] + 15))
# print(newindex)

# Convert the extended dimension x in the higher degree polynomial expression
X_extended_transform = poly.fit_transform(newindex.reshape(-1, 1))

# Prediction for future dates. Let's call it predicted values
y_predict = regression_model.predict(X_extended_transform)

# Print the last predicted value
# print("Closing price in the next 5 days: ", y_predict)

# Convert the days index back to dates index for plotting the graph
x = pd.to_datetime(df.index, origin="1970-01-01", unit="D")
future_x = pd.to_datetime(newindex, origin="1970-01-01", unit="D")
from sklearn.metrics import mean_absolute_percentage_error
mape = mean_absolute_percentage_error([84.983,84.8847,84.8847,85.1798,84.2945,84.2945,84.0978,83.9994,83.3109,84.5896,84.688,84.0978,83.8027,83.9011,84.983],y_predict)
# [33.4,33.3,33.4,33,33.2,33.1,32.8,32.7,32.5,33,33.15,33.65,33.8,33.9,34.5] ACB
# VNM [84.983,84.8847,84.8847,85.1798,84.2945,84.2945,84.0978,83.9994,83.3109,84.5896,84.688,84.0978,83.8027,83.9011,84.983]
print('MAPE: ',(mape))

# from matplotlib.pylab import rcParams

# rcParams["figure.figsize"] = 20, 10

# Plot the actual data
plt.figure(figsize=(16, 8))
plt.plot(x, df["Close"], label="Close Price History")

# Plot the regression model
plt.plot(x, y_learned, color="r", label="Mathematical Model")

# Plot the future predictions
plt.plot(future_x, y_predict, color="g", label="Future Predictions")

# Set the title of the graph
plt.suptitle("Stock Market Predictions", fontsize=16)

# Set the title of the graph window
fig = plt.gcf()
fig.canvas.set_window_title("Stock Market Predictions")

# display the legends
plt.legend()
# display the graph
plt.show()